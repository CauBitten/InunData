{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD1pkQolIsTm"
      },
      "source": [
        "# Instalação e Importação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting geopandas\n",
            "  Using cached geopandas-1.1.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.3.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "Requirement already satisfied: requests in /usr/lib/python3.13/site-packages (2.32.3)\n",
            "Collecting sqlalchemy\n",
            "  Using cached sqlalchemy-2.0.41-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting psycopg2-binary\n",
            "  Using cached psycopg2_binary-2.9.10-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting shapely\n",
            "  Using cached shapely-2.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.10.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting overpy\n",
            "  Using cached overpy-0.7-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting osmnx\n",
            "  Using cached osmnx-2.0.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting folium\n",
            "  Using cached folium-0.20.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting owslib\n",
            "  Using cached owslib-0.34.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting arcgis\n",
            "  Using cached arcgis-2.0.0.tar.gz (3.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/requirements.py\", line 36, in __init__\n",
            "    parsed = _parse_requirement(requirement_string)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/_parser.py\", line 62, in parse_requirement\n",
            "    return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/_parser.py\", line 80, in _parse_requirement\n",
            "    url, specifier, marker = _parse_requirement_details(tokenizer)\n",
            "                             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/_parser.py\", line 118, in _parse_requirement_details\n",
            "    specifier = _parse_specifier(tokenizer)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/_parser.py\", line 214, in _parse_specifier\n",
            "    parsed_specifiers = _parse_version_many(tokenizer)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/_parser.py\", line 229, in _parse_version_many\n",
            "    tokenizer.raise_syntax_error(\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
            "        \".* suffix can only be used with `==` or `!=` operators\",\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "        span_start=span_start,\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        span_end=tokenizer.position + 1,\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/_tokenizer.py\", line 167, in raise_syntax_error\n",
            "    raise ParserSyntaxError(\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "pip._vendor.packaging._tokenizer.ParserSyntaxError: .* suffix can only be used with `==` or `!=` operators\n",
            "    keyring >=19,<=21.8.*\n",
            "                 ~~~~~~~^\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/cli/base_command.py\", line 105, in _run_wrapper\n",
            "    status = _inner_run()\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/cli/base_command.py\", line 96, in _inner_run\n",
            "    return self.run(options, args)\n",
            "           ~~~~~~~~^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/commands/install.py\", line 379, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "        reqs, check_supported_wheels=not options.target_dir\n",
            "    )\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "                            ~~~~~~~~~~~~~~~~^\n",
            "        collected.requirements, max_rounds=limit_how_complex_resolution_can_be\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 397, in resolve\n",
            "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n",
            "    if not criterion.candidates:\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/resolvelib/structs.py\", line 156, in __bool__\n",
            "    return bool(self._sequence)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 174, in __bool__\n",
            "    return any(self)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 162, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "                       ^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 53, in _iter_built\n",
            "    candidate = func()\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 189, in _make_candidate_from_link\n",
            "    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n",
            "                                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
            "        link, template, name, version\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 235, in _make_base_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "                                       ~~~~~~~~~~~~~^\n",
            "        link,\n",
            "        ^^^^^\n",
            "    ...<3 lines>...\n",
            "        version=version,\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 304, in __init__\n",
            "    super().__init__(\n",
            "    ~~~~~~~~~~~~~~~~^\n",
            "        link=link,\n",
            "        ^^^^^^^^^^\n",
            "    ...<4 lines>...\n",
            "        version=version,\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 159, in __init__\n",
            "    self.dist = self._prepare()\n",
            "                ~~~~~~~~~~~~~^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 236, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 315, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 527, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 642, in _prepare_linked_requirement\n",
            "    dist = _get_prepared_distribution(\n",
            "        req,\n",
            "    ...<3 lines>...\n",
            "        self.check_build_deps,\n",
            "    )\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 72, in _get_prepared_distribution\n",
            "    abstract_dist.prepare_distribution_metadata(\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
            "        finder, build_isolation, check_build_deps\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 56, in prepare_distribution_metadata\n",
            "    self._install_build_reqs(finder)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 127, in _install_build_reqs\n",
            "    conflicting, missing = self.req.build_env.check_requirements(build_reqs)\n",
            "                           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/build_env.py\", line 187, in check_requirements\n",
            "    req = get_requirement(req_str)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/utils/packaging.py\", line 45, in get_requirement\n",
            "    return Requirement(req_string)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/requirements.py\", line 38, in __init__\n",
            "    raise InvalidRequirement(str(e)) from e\n",
            "pip._vendor.packaging.requirements.InvalidRequirement: .* suffix can only be used with `==` or `!=` operators\n",
            "    keyring >=19,<=21.8.*\n",
            "                 ~~~~~~~^\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install geopandas pandas requests sqlalchemy psycopg2-binary shapely matplotlib overpy osmnx folium owslib arcgis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9YW33cDXLgaX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.3.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "Requirement already satisfied: requests in /usr/lib/python3.13/site-packages (2.32.3)\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.10.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting geopandas\n",
            "  Using cached geopandas-1.1.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.3.1-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/lib/python3.13/site-packages (from pandas) (2.8.2)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.13/site-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.13/site-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.13/site-packages (from requests) (2.3.0)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Using cached contourpy-1.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Using cached fonttools-4.58.5-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (106 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Using cached kiwisolver-1.4.8-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/lib64/python3.13/site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3.13/site-packages (from matplotlib) (3.1.2)\n",
            "Collecting pyogrio>=0.7.2 (from geopandas)\n",
            "  Downloading pyogrio-0.11.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting pyproj>=3.5.0 (from geopandas)\n",
            "  Downloading pyproj-3.7.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Collecting shapely>=2.0.0 (from geopandas)\n",
            "  Using cached shapely-2.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/lib/python3.13/site-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Using cached pandas-2.3.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "Using cached matplotlib-3.10.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "Downloading geopandas-1.1.1-py3-none-any.whl (338 kB)\n",
            "Using cached numpy-2.3.1-cp313-cp313-manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Using cached contourpy-1.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached fonttools-4.58.5-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
            "Using cached kiwisolver-1.4.8-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "Downloading pyogrio-0.11.0-cp313-cp313-manylinux_2_28_x86_64.whl (27.7 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.7/27.7 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
            "\u001b[?25hDownloading pyproj-3.7.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading shapely-2.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Installing collected packages: pytz, tzdata, pyproj, numpy, kiwisolver, fonttools, cycler, shapely, pyogrio, pandas, contourpy, matplotlib, geopandas, seaborn\n",
            "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.5 geopandas-1.1.1 kiwisolver-1.4.8 matplotlib-3.10.3 numpy-2.3.1 pandas-2.3.1 pyogrio-0.11.0 pyproj-3.7.1 pytz-2025.2 seaborn-0.13.2 shapely-2.1.1 tzdata-2025.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas requests matplotlib geopandas numpy seaborn\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3qF5LRcB0Hh"
      },
      "source": [
        "# Análise de dados chuva e óbitos na RMR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jghaSZX30NQa"
      },
      "source": [
        "### ⚙️ Pipeline de Integração: Mortalidade e Pluviometria na RMR (PE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7SdEcOxK4pe",
        "outputId": "a0b0af9a-d104-424c-c33f-1c6a21333f03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📂 CARREGANDO DADOS DE MORTALIDADE\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_49795/2110664843.py:21: DtypeWarning: Columns (72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(caminho, encoding='latin-1', sep=',', dtype={'CODMUNRES': str})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dados de 2018 carregados | Registros: 62,011\n",
            "✅ Dados de 2019 carregados | Registros: 64,295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_49795/2110664843.py:21: DtypeWarning: Columns (71,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(caminho, encoding='latin-1', sep=',', dtype={'CODMUNRES': str})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dados de 2020 carregados | Registros: 76,574\n",
            "✅ Dados de 2021 carregados | Registros: 80,717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_49795/2110664843.py:21: DtypeWarning: Columns (71) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(caminho, encoding='latin-1', sep=',', dtype={'CODMUNRES': str})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dados de 2022 carregados | Registros: 72,011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_49795/2110664843.py:21: DtypeWarning: Columns (53,66,68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(caminho, encoding='latin-1', sep=',', dtype={'CODMUNRES': str})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dados de 2023 carregados | Registros: 68,527\n",
            "\n",
            "📊 DATASET CONSOLIDADO\n",
            "Registros totais: 424,135\n",
            "Período: 1012018 a 31122023\n",
            "\n",
            "🌧️ PROCESSANDO DADOS DE CHUVA\n",
            "==================================================\n",
            "\n",
            "✅ Cidades padronizadas: ['Abreu e Lima' 'Araçoiaba' 'Cabo' 'Cabo de Santo Agostinho' 'Camaragibe'\n",
            " 'Goiana (Itapirema - IPA)' 'Goiana - PCD' 'Igarassu'\n",
            " 'Igarassu (Bar.Catucá)' 'Igarassu (Usina São José)' 'Ipojuca' 'Itamaracá'\n",
            " 'Itapissuma' 'Jaboatão dos Guararapes'\n",
            " 'Jaboatão dos Guararapes (Bar.Duas Unas)' 'Moreno' 'Olinda'\n",
            " 'Olinda (Academia Santa Gertrudes)' 'Olinda (Alto da Bondade)' 'Paulista'\n",
            " 'Recife' 'Recife (Alto da Brasileira)' 'São Lourenço da Mata'\n",
            " 'Olinda (Jardim Atlântico)']\n",
            "✅ Formato temporal: ['01/2018' '01/2019' '01/2020' '01/2021' '01/2022']\n",
            "✅ Exemplo de dados:\n",
            "       Mês/Ano                              Posto Unnamed: 0 Código     1    2  \\\n",
            "140   01/2024                       Abreu e Lima        928    198  68.0  1.0   \n",
            "1574  09/2024                             Recife       1186    196   0.0  0.0   \n",
            "1711  10/2023  Olinda (Academia Santa Gertrudes)        862    551   0.0  0.0   \n",
            "\n",
            "        3    4    5     6  ...   23   24    25    26    27   28    29    30  \\\n",
            "140   0.0  0.0  0.0   0.0  ...  0.0  0.0  18.0   2.0   0.0  0.0  31.0   0.0   \n",
            "1574  0.0  0.0  0.0   4.0  ...  0.0  0.0   0.0  18.0  23.0  0.0   0.0  35.0   \n",
            "1711  0.0  0.0  0.0  36.0  ...  0.0  0.0   0.0   0.0  19.0  5.0  10.0   0.0   \n",
            "\n",
            "       31  Acumulado  \n",
            "140   0.0    87509.0  \n",
            "1574  NaN    83545.0  \n",
            "1711  0.0    77952.0  \n",
            "\n",
            "[3 rows x 36 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_49795/2110664843.py:199: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_pe['CODMUNOCOR'] = df_pe['CODMUNOCOR'].astype(str).str[:6]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Datas convertidas (exemplo): 1   2018-04-16\n",
            "4   2018-09-08\n",
            "5   2018-01-10\n",
            "Name: DTOBITO, dtype: datetime64[ns]\n",
            "\n",
            "🌆 Municípios normalizados: ['São Lourenço da Mata' 'Recife' 'Jaboatão dos Guararapes'\n",
            " 'Ilha de Itamaracá' 'Ipojuca' 'Cabo de Santo Agostinho' 'Olinda'\n",
            " 'Camaragibe' 'Paulista' 'Araçoiaba' 'Itapissuma' 'Abreu e Lima'\n",
            " 'Igarassu' 'Moreno']\n",
            "\n",
            "👥 Distribuição por sexo:\n",
            " SEXO\n",
            "Masculino    120502\n",
            "Feminino     108137\n",
            "Ignorado        134\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# ========================================================\n",
        "#                  CONFIGURAÇÕES INICIAIS\n",
        "# ========================================================\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams['figure.figsize'] = (16, 8)\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# ========================================================\n",
        "#               CARREGAMENTO E PREPARAÇÃO DOS DADOS\n",
        "# ========================================================\n",
        "\n",
        "def carregar_dados_mortalidade():\n",
        "    \"\"\"Carrega e processa os dados de mortalidade\"\"\"\n",
        "    print(\"\\n📂 CARREGANDO DADOS DE MORTALIDADE\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    dfs = []\n",
        "    for ano in range(2018, 2024):\n",
        "        caminho = f'../data/MortalidadeBrasil/ETLSIM.DORES_PE_{ano}_t.csv'\n",
        "        df = pd.read_csv(caminho, encoding='latin-1', sep=',', dtype={'CODMUNRES': str})\n",
        "        dfs.append(df)\n",
        "        print(f\"✅ Dados de {ano} carregados | Registros: {len(df):,}\")\n",
        "\n",
        "    df_completo = pd.concat(dfs)\n",
        "    print(\"\\n📊 DATASET CONSOLIDADO\")\n",
        "    print(f\"Registros totais: {len(df_completo):,}\")\n",
        "    print(f\"Período: {df_completo['DTOBITO'].min()} a {df_completo['DTOBITO'].max()}\")\n",
        "\n",
        "    return df_completo\n",
        "\n",
        "def preprocessar_dados_chuva():\n",
        "    # 1. Carregar dados brutos\n",
        "    df1 = pd.read_csv(\n",
        "        '../data/Chuvas/Chuvas18-21.csv',\n",
        "        sep=',',\n",
        "        decimal=',',\n",
        "        encoding='utf-8',\n",
        "        dtype=str\n",
        "    )\n",
        "\n",
        "    df2 = pd.read_csv(\n",
        "        '../data/Chuvas/Chuvas21-25.csv',\n",
        "        sep=',',\n",
        "        decimal=',',\n",
        "        encoding='utf-8',\n",
        "        dtype=str\n",
        "    )\n",
        "\n",
        "    # 2. Unificação e limpeza\n",
        "    df_chuva = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "    # 3. Padronização temporal\n",
        "    meses = {\n",
        "        'jan./': '01/', 'fev./': '02/', 'mar./': '03/', 'abr./': '04/',\n",
        "        'mai./': '05/', 'jun./': '06/', 'jul./': '07/', 'ago./': '08/',\n",
        "        'set./': '09/', 'out./': '10/', 'nov./': '11/', 'dez./': '12/'\n",
        "    }\n",
        "\n",
        "    for old, new in meses.items():\n",
        "        df_chuva['Mês/Ano'] = df_chuva['Mês/Ano'].str.replace(old, new)\n",
        "\n",
        "    # 4. Normalização de nomes geográficos\n",
        "    mapeamento_cidades = {\n",
        "        'Araçoiaba (Granja Cristo Redentor)': 'Araçoiaba',\n",
        "        'Cabo (Barragem de Gurjaú)': 'Cabo de Santo Agostinho',\n",
        "        'Cabo (Barragem de Suape)': 'Cabo de Santo Agostinho',\n",
        "        'Cabo (Pirapama)': 'Cabo de Santo Agostinho',\n",
        "        'Ipojuca (Suape) - PCD': 'Ipojuca',\n",
        "        'Jaboatão (Cidade da Copa) - PCD': 'Jaboatão dos Guararapes',\n",
        "        'Recife (Codecipe / Santo Amaro)': 'Recife',\n",
        "        'Recife (Várzea)': 'Recife',\n",
        "        'São Lourenço da Mata (Tapacurá)': 'São Lourenço da Mata'\n",
        "    }\n",
        "\n",
        "    df_chuva['Posto'] = df_chuva['Posto'].replace(mapeamento_cidades)\n",
        "\n",
        "    # 5. Conversão numérica robusta\n",
        "    day_cols = [str(i) for i in range(1,32)]\n",
        "    for col in day_cols + ['Acumulado']:\n",
        "        df_chuva[col] = (\n",
        "            df_chuva[col]\n",
        "            .str.replace('[^0-9,]', '', regex=True)\n",
        "            .str.replace(',', '.')\n",
        "            .replace('', '0')\n",
        "            .astype(float)\n",
        "        )\n",
        "\n",
        "    # 6. Consistência final\n",
        "    df_chuva = df_chuva.groupby(['Mês/Ano', 'Posto']).first().reset_index()\n",
        "\n",
        "    return df_chuva\n",
        "\n",
        "def processar_dados_chuva():\n",
        "    \"\"\"Processa e formata os dados pluviométricos\"\"\"\n",
        "    print(\"\\n🌧️ PROCESSANDO DADOS DE CHUVA\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Código de pré-processamento anterior (mantido)\n",
        "    df_chuva = preprocessar_dados_chuva()\n",
        "    print(\"\\n✅ Cidades padronizadas:\", df_chuva['Posto'].unique())\n",
        "    print(\"✅ Formato temporal:\", df_chuva['Mês/Ano'].unique()[:5])\n",
        "    print(\"✅ Exemplo de dados:\\n\", df_chuva.sample(3))\n",
        "\n",
        "    # Converter o formato wide para long (uma linha por dia/mês/cidade)\n",
        "    df_chuva_reform = df_chuva.melt(\n",
        "        id_vars=['Posto', 'Mês/Ano'],\n",
        "        value_vars=[str(i) for i in range(1, 32)],\n",
        "        var_name='Dia',\n",
        "        value_name='Chuva_mm'\n",
        "    )\n",
        "\n",
        "    # Converter dia para inteiro\n",
        "    df_chuva_reform['Dia'] = df_chuva_reform['Dia'].astype(int)\n",
        "\n",
        "    return df_chuva_reform\n",
        "\n",
        "def corrigir_df_rmr(df):\n",
        "    # 1. Converter datas\n",
        "    df['DTOBITO'] = pd.to_datetime(\n",
        "        df['DTOBITO'].astype(str).str.zfill(8),\n",
        "        format='%d%m%Y',\n",
        "        errors='coerce'\n",
        "    )\n",
        "\n",
        "    # 2. Ajustar encoding\n",
        "    df['ocor_MUNNOME'] = (\n",
        "        df['ocor_MUNNOME']\n",
        "        .str.encode('latin-1').str.decode('utf-8', errors='ignore')\n",
        "        .replace({\n",
        "            'SÃ£o LourenÃ§o da Mata': 'São Lourenço da Mata',\n",
        "            'JaboatÃ£o dos Guararapes': 'Jaboatão dos Guararapes',\n",
        "            'Ilha de ItamaracÃ¡': 'Ilha de Itamaracá',\n",
        "            'AraÃ§oiaba': 'Araçoiaba'\n",
        "        })\n",
        "    )\n",
        "\n",
        "    # 3. Mapear variáveis categóricas\n",
        "    df['SEXO'] = df['SEXO'].map({\n",
        "        1: 'Masculino',\n",
        "        2: 'Feminino',\n",
        "        0: 'Ignorado'\n",
        "    })\n",
        "\n",
        "    # 4. Corrigir idade (supondo que idade está em dias)\n",
        "    if 'idade_obito_anos' not in df.columns:\n",
        "        df['idade_obito_anos'] = df['IDADE'] // 365  # Se IDADE estiver em dias\n",
        "\n",
        "    # 5. Remover colunas vazias\n",
        "    cols_vazias = [col for col in df.columns if df[col].isna().all()]\n",
        "    df = df.drop(columns=cols_vazias)\n",
        "\n",
        "    return df\n",
        "\n",
        "# =====================================\n",
        "# DADOS DE REFERÊNCIA (RMR - Pernambuco)\n",
        "# =====================================\n",
        "# Códigos IBGE dos municípios da RMR (6 dígitos, como aparece no seu DataFrame)\n",
        "codigos_rmr_6digitos = [\n",
        "    '261160',  # Recife\n",
        "    '260790',  # Jaboatão dos Guararapes\n",
        "    '260960',  # Olinda\n",
        "    '261070',  # Paulista\n",
        "    '260290',  # Cabo de Santo Agostinho\n",
        "    '260345',  # Camaragibe\n",
        "    '261370',  # São Lourenço da Mata\n",
        "    '260680',  # Igarassu\n",
        "    '260005',  # Abreu e Lima\n",
        "    '260720',  # Ipojuca\n",
        "    '260940',  # Moreno\n",
        "    '260105',  # Araçoiaba\n",
        "    '260775',  # Itapissuma\n",
        "    '260760'   # Itamaracá\n",
        "]\n",
        "\n",
        "# Nomes correspondentes aos códigos\n",
        "nomes_municipios = {\n",
        "    '260005': 'Abreu e Lima',\n",
        "    '260105': 'Araçoiaba',\n",
        "    '260290': 'Cabo de Santo Agostinho',\n",
        "    '260345': 'Camaragibe',\n",
        "    '260680': 'Igarassu',\n",
        "    '260720': 'Ipojuca',\n",
        "    '260760': 'Itamaracá',\n",
        "    '260775': 'Itapissuma',\n",
        "    '260790': 'Jaboatão dos Guararapes',\n",
        "    '260940': 'Moreno',\n",
        "    '260960': 'Olinda',\n",
        "    '261070': 'Paulista',\n",
        "    '261160': 'Recife',\n",
        "    '261370': 'São Lourenço da Mata'\n",
        "}\n",
        "\n",
        "def processar_dados_mortalidade(df):\n",
        "    # Deixar apenas Pernambuco\n",
        "    df_pe = df[df['ocor_SIGLA_UF'] == 'PE']\n",
        "\n",
        "    # Criar uma coluna temporária com os 6 primeiros dígitos de CODMUNOCOR\n",
        "    df_pe['CODMUNOCOR'] = df_pe['CODMUNOCOR'].astype(str).str[:6]\n",
        "\n",
        "    # Filtrar apenas os municípios da RMR\n",
        "    df_rmr = df_pe[df_pe['CODMUNOCOR'].isin(codigos_rmr_6digitos)].copy()\n",
        "\n",
        "    # Adicionar nomes dos municípios\n",
        "    df_rmr['NOME_MUNICIPIO'] = df_rmr['CODMUNOCOR'].map(nomes_municipios)\n",
        "\n",
        "    # Aplicar correções\n",
        "    df_rmr_corrigido = corrigir_df_rmr(df_rmr)\n",
        "\n",
        "    # Verificar resultados\n",
        "    print(\"\\n🔍 Datas convertidas (exemplo):\", df_rmr_corrigido['DTOBITO'].head(3))\n",
        "    print(\"\\n🌆 Municípios normalizados:\", df_rmr_corrigido['ocor_MUNNOME'].unique())\n",
        "    print(\"\\n👥 Distribuição por sexo:\\n\", df_rmr_corrigido['SEXO'].value_counts())\n",
        "\n",
        "    # Adicionar ao código de correção (etapa 2)\n",
        "    # Modificar df_rmr_corrigido em vez de df\n",
        "    df_rmr_corrigido['ocor_MUNNOME'] = df_rmr_corrigido['ocor_MUNNOME'].replace('Ilha de Itamaracá', 'Itamaracá')\n",
        "\n",
        "    df_analise = df_rmr_corrigido[df_rmr_corrigido['SEXO'].isin(['Masculino', 'Feminino'])]\n",
        "\n",
        "    # Criar colunas de junção\n",
        "    df_rmr_corrigido['MES_ANO'] = df_rmr_corrigido['DTOBITO'].dt.strftime('%m/%Y')\n",
        "    df_rmr_corrigido['DIA'] = df_rmr_corrigido['DTOBITO'].dt.day\n",
        "\n",
        "    # Criar colunas de junção no df_rmr_corrigido\n",
        "    df_rmr_corrigido['MES_ANO'] = df_rmr_corrigido['DTOBITO'].dt.strftime('%m/%Y')\n",
        "    df_rmr_corrigido['DIA'] = df_rmr_corrigido['DTOBITO'].dt.day\n",
        "\n",
        "    return df_rmr_corrigido\n",
        "\n",
        "# ========================================================\n",
        "#               FUNÇÃO PRINCIPAL\n",
        "# ========================================================\n",
        "\n",
        "# Etapa 1: Carregar dados\n",
        "df_mortalidade = carregar_dados_mortalidade()\n",
        "df_chuva = processar_dados_chuva()\n",
        "\n",
        "# Etapa 2: Processamento e merge\n",
        "df_processado = processar_dados_mortalidade(df_mortalidade)\n",
        "df_final = pd.merge(\n",
        "    df_processado,\n",
        "    df_chuva,\n",
        "    left_on=['ocor_MUNNOME', 'MES_ANO', 'DIA'],\n",
        "    right_on=['Posto', 'Mês/Ano', 'Dia'],\n",
        "    how='left'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTW4NMF70UQw"
      },
      "source": [
        "### 📊 Comparação Diária: Óbitos e Chuvas na RMR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uzzfVSI2hu-3"
      },
      "outputs": [],
      "source": [
        "def comparar_rmr_dia(data_input, cidade, df, top_n=10):\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    rmr_cidades = [\n",
        "        'Recife', 'Igarassu', 'Camaragibe', 'Araçoiaba', 'Cabo de Santo Agostinho',\n",
        "        'São Lourenço da Mata', 'Itamaracá', 'Jaboatão dos Guararapes', 'Paulista',\n",
        "        'Ipojuca', 'Moreno', 'Olinda', 'Abreu e Lima', 'Itapissuma'\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        data = pd.to_datetime(data_input).date()\n",
        "    except:\n",
        "        print(\"❌ Data inválida. Use o formato 'YYYY-MM-DD'.\")\n",
        "        return\n",
        "\n",
        "    df_rmr_dia = df[\n",
        "        (df['ocor_MUNNOME'].isin(rmr_cidades)) &\n",
        "        (pd.to_datetime(df['data_obito']).dt.date == data)\n",
        "    ]\n",
        "\n",
        "    if df_rmr_dia.empty:\n",
        "        print(f\"⚠️ Nenhum dado encontrado para a RMR em {data}.\")\n",
        "        return\n",
        "\n",
        "    dados_cidade = df_rmr_dia[df_rmr_dia['ocor_MUNNOME'].str.upper() == cidade.upper()]\n",
        "\n",
        "    if dados_cidade.empty:\n",
        "        print(f\"⚠️ Nenhum dado encontrado para {cidade.title()} em {data}.\")\n",
        "        return\n",
        "\n",
        "    # Preparar dados\n",
        "    causas = dados_cidade['CAUSABAS'].value_counts().head(top_n)\n",
        "    agrupado = df_rmr_dia.groupby('ocor_MUNNOME').agg({\n",
        "        'DTOBITO': 'count',\n",
        "        'Chuva_mm': 'mean'\n",
        "    }).rename(columns={'DTOBITO': 'Total_Obitos', 'Chuva_mm': 'Media_Chuva_mm'}).fillna(0)\n",
        "\n",
        "    rmr_existentes = [c for c in rmr_cidades if c in agrupado.index]\n",
        "    agrupado = agrupado.loc[rmr_existentes]\n",
        "    cores = ['red' if cidade.lower() != mun.lower() else 'darkblue' for mun in agrupado.index]\n",
        "\n",
        "    # Criar dois gráficos lado a lado\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "    # Pizza\n",
        "    ax1.pie(causas, labels=causas.index, autopct='%1.1f%%', startangle=140,\n",
        "            colors=sns.color_palette('Reds', n_colors=top_n))\n",
        "    ax1.set_title(f'{cidade.title()} - {data}\\nTop {top_n} Causas de Óbito (CAUSABAS)')\n",
        "\n",
        "    # Barras + linha\n",
        "    sns.barplot(x=agrupado.index, y=agrupado['Total_Obitos'], palette=cores, ax=ax2)\n",
        "    ax2.set_ylabel('Total de Óbitos', color='black')\n",
        "    ax2.set_xlabel('')\n",
        "    ax2.set_xticklabels(agrupado.index, rotation=45, ha='right')\n",
        "\n",
        "    ax3 = ax2.twinx()\n",
        "    sns.lineplot(x=agrupado.index, y=agrupado['Media_Chuva_mm'], color='blue', marker='o', label='Chuva Média (mm)', ax=ax3)\n",
        "    ax3.set_ylabel('Média de Chuva (mm)', color='blue')\n",
        "    ax3.tick_params(axis='y', labelcolor='blue')\n",
        "\n",
        "    ax2.set_title(f'Comparativo por Cidade na RMR - {data}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Resumo\n",
        "    print(f\"\\n📅 Data: {data}\")\n",
        "    print(f\"🏙️ Cidade: {cidade.title()}\")\n",
        "    print(f\"💀 Óbitos: {len(dados_cidade)}\")\n",
        "    print(f\"☔ Chuva: {dados_cidade['Chuva_mm'].mean():.2f} mm\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjJWUKe5HWMl"
      },
      "source": [
        "# Interações e Gráficos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MofbDYnm0b5D"
      },
      "source": [
        "### 🔗 Correlação entre Chuva e Óbitos por Causas Infecciosas (CID-W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBL8y444Wwp0",
        "outputId": "e4a6f035-aa29-4850-f14b-81b407689e65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recife: -0.14\n",
            "Igarassu: -0.22\n",
            "Camaragibe: -0.34\n",
            "Araçoiaba: -0.17\n",
            "Cabo de Santo Agostinho: -0.19\n",
            "São Lourenço da Mata: -0.27\n",
            "Itamaracá: 0.18\n",
            "Jaboatão dos Guararapes: -0.13\n",
            "Paulista: -0.19\n",
            "Ipojuca: -0.27\n",
            "Moreno: -0.13\n",
            "Olinda: -0.07\n",
            "Abreu e Lima: 0.02\n",
            "Itapissuma: -0.37\n"
          ]
        }
      ],
      "source": [
        "df_final = df_final[df_final['CAUSABAS'].str.startswith(('W'), na=False)]\n",
        "df_final = df_final.rename(columns={'CONTADOR': 'Total_Obitos'})\n",
        "\n",
        "for cidade in df_final['ocor_MUNNOME'].unique():\n",
        "    df_cidade = df_final[df_final['ocor_MUNNOME'] == cidade]\n",
        "    corr_local = df_cidade[['Chuva_mm', 'Total_Obitos']].corr().iloc[0, 1]\n",
        "    print(f\"{cidade}: {corr_local:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "qTiGt49hdNIN",
        "outputId": "ce88e7ba-7328-4719-f937-207baba2f88b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Nenhum dado encontrado para a RMR em 2024-05-01.\n"
          ]
        }
      ],
      "source": [
        "comparar_rmr_dia(\"2024-05-1\", \"Recife\", df_final)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "uD1pkQolIsTm",
        "Bhzbfm970Ivp",
        "jghaSZX30NQa",
        "kTW4NMF70UQw",
        "GjJWUKe5HWMl"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
