{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD1pkQolIsTm"
      },
      "source": [
        "# Instala√ß√£o e Importa√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting geopandas\n",
            "  Using cached geopandas-1.1.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.3.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "Requirement already satisfied: requests in /usr/lib/python3.13/site-packages (2.32.3)\n",
            "Collecting sqlalchemy\n",
            "  Using cached sqlalchemy-2.0.41-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting psycopg2-binary\n",
            "  Using cached psycopg2_binary-2.9.10-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting shapely\n",
            "  Using cached shapely-2.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.10.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting overpy\n",
            "  Using cached overpy-0.7-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting osmnx\n",
            "  Using cached osmnx-2.0.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting folium\n",
            "  Using cached folium-0.20.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting owslib\n",
            "  Using cached owslib-0.34.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting arcgis\n",
            "  Using cached arcgis-2.0.0.tar.gz (3.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/requirements.py\", line 36, in __init__\n",
            "    parsed = _parse_requirement(requirement_string)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/_parser.py\", line 62, in parse_requirement\n",
            "    return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/_parser.py\", line 80, in _parse_requirement\n",
            "    url, specifier, marker = _parse_requirement_details(tokenizer)\n",
            "                             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/_parser.py\", line 118, in _parse_requirement_details\n",
            "    specifier = _parse_specifier(tokenizer)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/_parser.py\", line 214, in _parse_specifier\n",
            "    parsed_specifiers = _parse_version_many(tokenizer)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/_parser.py\", line 229, in _parse_version_many\n",
            "    tokenizer.raise_syntax_error(\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
            "        \".* suffix can only be used with `==` or `!=` operators\",\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "        span_start=span_start,\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        span_end=tokenizer.position + 1,\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/_tokenizer.py\", line 167, in raise_syntax_error\n",
            "    raise ParserSyntaxError(\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "pip._vendor.packaging._tokenizer.ParserSyntaxError: .* suffix can only be used with `==` or `!=` operators\n",
            "    keyring >=19,<=21.8.*\n",
            "                 ~~~~~~~^\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/cli/base_command.py\", line 105, in _run_wrapper\n",
            "    status = _inner_run()\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/cli/base_command.py\", line 96, in _inner_run\n",
            "    return self.run(options, args)\n",
            "           ~~~~~~~~^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/commands/install.py\", line 379, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "        reqs, check_supported_wheels=not options.target_dir\n",
            "    )\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "                            ~~~~~~~~~~~~~~~~^\n",
            "        collected.requirements, max_rounds=limit_how_complex_resolution_can_be\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 397, in resolve\n",
            "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n",
            "    if not criterion.candidates:\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/resolvelib/structs.py\", line 156, in __bool__\n",
            "    return bool(self._sequence)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 174, in __bool__\n",
            "    return any(self)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 162, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "                       ^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 53, in _iter_built\n",
            "    candidate = func()\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 189, in _make_candidate_from_link\n",
            "    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n",
            "                                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
            "        link, template, name, version\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 235, in _make_base_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "                                       ~~~~~~~~~~~~~^\n",
            "        link,\n",
            "        ^^^^^\n",
            "    ...<3 lines>...\n",
            "        version=version,\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 304, in __init__\n",
            "    super().__init__(\n",
            "    ~~~~~~~~~~~~~~~~^\n",
            "        link=link,\n",
            "        ^^^^^^^^^^\n",
            "    ...<4 lines>...\n",
            "        version=version,\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 159, in __init__\n",
            "    self.dist = self._prepare()\n",
            "                ~~~~~~~~~~~~~^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 236, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 315, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 527, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 642, in _prepare_linked_requirement\n",
            "    dist = _get_prepared_distribution(\n",
            "        req,\n",
            "    ...<3 lines>...\n",
            "        self.check_build_deps,\n",
            "    )\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 72, in _get_prepared_distribution\n",
            "    abstract_dist.prepare_distribution_metadata(\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
            "        finder, build_isolation, check_build_deps\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 56, in prepare_distribution_metadata\n",
            "    self._install_build_reqs(finder)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 127, in _install_build_reqs\n",
            "    conflicting, missing = self.req.build_env.check_requirements(build_reqs)\n",
            "                           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/build_env.py\", line 187, in check_requirements\n",
            "    req = get_requirement(req_str)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_internal/utils/packaging.py\", line 45, in get_requirement\n",
            "    return Requirement(req_string)\n",
            "  File \"/usr/lib/python3.13/site-packages/pip/_vendor/packaging/requirements.py\", line 38, in __init__\n",
            "    raise InvalidRequirement(str(e)) from e\n",
            "pip._vendor.packaging.requirements.InvalidRequirement: .* suffix can only be used with `==` or `!=` operators\n",
            "    keyring >=19,<=21.8.*\n",
            "                 ~~~~~~~^\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install geopandas pandas requests sqlalchemy psycopg2-binary shapely matplotlib overpy osmnx folium owslib arcgis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9YW33cDXLgaX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.3.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "Requirement already satisfied: requests in /usr/lib/python3.13/site-packages (2.32.3)\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.10.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting geopandas\n",
            "  Using cached geopandas-1.1.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.3.1-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/lib/python3.13/site-packages (from pandas) (2.8.2)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.13/site-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.13/site-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.13/site-packages (from requests) (2.3.0)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Using cached contourpy-1.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Using cached fonttools-4.58.5-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (106 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Using cached kiwisolver-1.4.8-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/lib64/python3.13/site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3.13/site-packages (from matplotlib) (3.1.2)\n",
            "Collecting pyogrio>=0.7.2 (from geopandas)\n",
            "  Downloading pyogrio-0.11.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting pyproj>=3.5.0 (from geopandas)\n",
            "  Downloading pyproj-3.7.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Collecting shapely>=2.0.0 (from geopandas)\n",
            "  Using cached shapely-2.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/lib/python3.13/site-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Using cached pandas-2.3.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "Using cached matplotlib-3.10.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "Downloading geopandas-1.1.1-py3-none-any.whl (338 kB)\n",
            "Using cached numpy-2.3.1-cp313-cp313-manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Using cached contourpy-1.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached fonttools-4.58.5-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
            "Using cached kiwisolver-1.4.8-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "Downloading pyogrio-0.11.0-cp313-cp313-manylinux_2_28_x86_64.whl (27.7 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m27.7/27.7 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
            "\u001b[?25hDownloading pyproj-3.7.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading shapely-2.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Installing collected packages: pytz, tzdata, pyproj, numpy, kiwisolver, fonttools, cycler, shapely, pyogrio, pandas, contourpy, matplotlib, geopandas, seaborn\n",
            "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.5 geopandas-1.1.1 kiwisolver-1.4.8 matplotlib-3.10.3 numpy-2.3.1 pandas-2.3.1 pyogrio-0.11.0 pyproj-3.7.1 pytz-2025.2 seaborn-0.13.2 shapely-2.1.1 tzdata-2025.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas requests matplotlib geopandas numpy seaborn\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3qF5LRcB0Hh"
      },
      "source": [
        "# An√°lise de dados chuva e √≥bitos na RMR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jghaSZX30NQa"
      },
      "source": [
        "### ‚öôÔ∏è Pipeline de Integra√ß√£o: Mortalidade e Pluviometria na RMR (PE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7SdEcOxK4pe",
        "outputId": "a0b0af9a-d104-424c-c33f-1c6a21333f03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÇ CARREGANDO DADOS DE MORTALIDADE\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_49795/2110664843.py:21: DtypeWarning: Columns (72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(caminho, encoding='latin-1', sep=',', dtype={'CODMUNRES': str})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dados de 2018 carregados | Registros: 62,011\n",
            "‚úÖ Dados de 2019 carregados | Registros: 64,295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_49795/2110664843.py:21: DtypeWarning: Columns (71,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(caminho, encoding='latin-1', sep=',', dtype={'CODMUNRES': str})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dados de 2020 carregados | Registros: 76,574\n",
            "‚úÖ Dados de 2021 carregados | Registros: 80,717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_49795/2110664843.py:21: DtypeWarning: Columns (71) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(caminho, encoding='latin-1', sep=',', dtype={'CODMUNRES': str})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dados de 2022 carregados | Registros: 72,011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_49795/2110664843.py:21: DtypeWarning: Columns (53,66,68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(caminho, encoding='latin-1', sep=',', dtype={'CODMUNRES': str})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dados de 2023 carregados | Registros: 68,527\n",
            "\n",
            "üìä DATASET CONSOLIDADO\n",
            "Registros totais: 424,135\n",
            "Per√≠odo: 1012018 a 31122023\n",
            "\n",
            "üåßÔ∏è PROCESSANDO DADOS DE CHUVA\n",
            "==================================================\n",
            "\n",
            "‚úÖ Cidades padronizadas: ['Abreu e Lima' 'Ara√ßoiaba' 'Cabo' 'Cabo de Santo Agostinho' 'Camaragibe'\n",
            " 'Goiana (Itapirema - IPA)' 'Goiana - PCD' 'Igarassu'\n",
            " 'Igarassu (Bar.Catuc√°)' 'Igarassu (Usina S√£o Jos√©)' 'Ipojuca' 'Itamarac√°'\n",
            " 'Itapissuma' 'Jaboat√£o dos Guararapes'\n",
            " 'Jaboat√£o dos Guararapes (Bar.Duas Unas)' 'Moreno' 'Olinda'\n",
            " 'Olinda (Academia Santa Gertrudes)' 'Olinda (Alto da Bondade)' 'Paulista'\n",
            " 'Recife' 'Recife (Alto da Brasileira)' 'S√£o Louren√ßo da Mata'\n",
            " 'Olinda (Jardim Atl√¢ntico)']\n",
            "‚úÖ Formato temporal: ['01/2018' '01/2019' '01/2020' '01/2021' '01/2022']\n",
            "‚úÖ Exemplo de dados:\n",
            "       M√™s/Ano                              Posto Unnamed: 0 C√≥digo     1    2  \\\n",
            "140   01/2024                       Abreu e Lima        928    198  68.0  1.0   \n",
            "1574  09/2024                             Recife       1186    196   0.0  0.0   \n",
            "1711  10/2023  Olinda (Academia Santa Gertrudes)        862    551   0.0  0.0   \n",
            "\n",
            "        3    4    5     6  ...   23   24    25    26    27   28    29    30  \\\n",
            "140   0.0  0.0  0.0   0.0  ...  0.0  0.0  18.0   2.0   0.0  0.0  31.0   0.0   \n",
            "1574  0.0  0.0  0.0   4.0  ...  0.0  0.0   0.0  18.0  23.0  0.0   0.0  35.0   \n",
            "1711  0.0  0.0  0.0  36.0  ...  0.0  0.0   0.0   0.0  19.0  5.0  10.0   0.0   \n",
            "\n",
            "       31  Acumulado  \n",
            "140   0.0    87509.0  \n",
            "1574  NaN    83545.0  \n",
            "1711  0.0    77952.0  \n",
            "\n",
            "[3 rows x 36 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_49795/2110664843.py:199: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_pe['CODMUNOCOR'] = df_pe['CODMUNOCOR'].astype(str).str[:6]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç Datas convertidas (exemplo): 1   2018-04-16\n",
            "4   2018-09-08\n",
            "5   2018-01-10\n",
            "Name: DTOBITO, dtype: datetime64[ns]\n",
            "\n",
            "üåÜ Munic√≠pios normalizados: ['S√£o Louren√ßo da Mata' 'Recife' 'Jaboat√£o dos Guararapes'\n",
            " 'Ilha de Itamarac√°' 'Ipojuca' 'Cabo de Santo Agostinho' 'Olinda'\n",
            " 'Camaragibe' 'Paulista' 'Ara√ßoiaba' 'Itapissuma' 'Abreu e Lima'\n",
            " 'Igarassu' 'Moreno']\n",
            "\n",
            "üë• Distribui√ß√£o por sexo:\n",
            " SEXO\n",
            "Masculino    120502\n",
            "Feminino     108137\n",
            "Ignorado        134\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# ========================================================\n",
        "#                  CONFIGURA√á√ïES INICIAIS\n",
        "# ========================================================\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams['figure.figsize'] = (16, 8)\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# ========================================================\n",
        "#               CARREGAMENTO E PREPARA√á√ÉO DOS DADOS\n",
        "# ========================================================\n",
        "\n",
        "def carregar_dados_mortalidade():\n",
        "    \"\"\"Carrega e processa os dados de mortalidade\"\"\"\n",
        "    print(\"\\nüìÇ CARREGANDO DADOS DE MORTALIDADE\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    dfs = []\n",
        "    for ano in range(2018, 2024):\n",
        "        caminho = f'../data/MortalidadeBrasil/ETLSIM.DORES_PE_{ano}_t.csv'\n",
        "        df = pd.read_csv(caminho, encoding='latin-1', sep=',', dtype={'CODMUNRES': str})\n",
        "        dfs.append(df)\n",
        "        print(f\"‚úÖ Dados de {ano} carregados | Registros: {len(df):,}\")\n",
        "\n",
        "    df_completo = pd.concat(dfs)\n",
        "    print(\"\\nüìä DATASET CONSOLIDADO\")\n",
        "    print(f\"Registros totais: {len(df_completo):,}\")\n",
        "    print(f\"Per√≠odo: {df_completo['DTOBITO'].min()} a {df_completo['DTOBITO'].max()}\")\n",
        "\n",
        "    return df_completo\n",
        "\n",
        "def preprocessar_dados_chuva():\n",
        "    # 1. Carregar dados brutos\n",
        "    df1 = pd.read_csv(\n",
        "        '../data/Chuvas/Chuvas18-21.csv',\n",
        "        sep=',',\n",
        "        decimal=',',\n",
        "        encoding='utf-8',\n",
        "        dtype=str\n",
        "    )\n",
        "\n",
        "    df2 = pd.read_csv(\n",
        "        '../data/Chuvas/Chuvas21-25.csv',\n",
        "        sep=',',\n",
        "        decimal=',',\n",
        "        encoding='utf-8',\n",
        "        dtype=str\n",
        "    )\n",
        "\n",
        "    # 2. Unifica√ß√£o e limpeza\n",
        "    df_chuva = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "    # 3. Padroniza√ß√£o temporal\n",
        "    meses = {\n",
        "        'jan./': '01/', 'fev./': '02/', 'mar./': '03/', 'abr./': '04/',\n",
        "        'mai./': '05/', 'jun./': '06/', 'jul./': '07/', 'ago./': '08/',\n",
        "        'set./': '09/', 'out./': '10/', 'nov./': '11/', 'dez./': '12/'\n",
        "    }\n",
        "\n",
        "    for old, new in meses.items():\n",
        "        df_chuva['M√™s/Ano'] = df_chuva['M√™s/Ano'].str.replace(old, new)\n",
        "\n",
        "    # 4. Normaliza√ß√£o de nomes geogr√°ficos\n",
        "    mapeamento_cidades = {\n",
        "        'Ara√ßoiaba (Granja Cristo Redentor)': 'Ara√ßoiaba',\n",
        "        'Cabo (Barragem de Gurja√∫)': 'Cabo de Santo Agostinho',\n",
        "        'Cabo (Barragem de Suape)': 'Cabo de Santo Agostinho',\n",
        "        'Cabo (Pirapama)': 'Cabo de Santo Agostinho',\n",
        "        'Ipojuca (Suape) - PCD': 'Ipojuca',\n",
        "        'Jaboat√£o (Cidade da Copa) - PCD': 'Jaboat√£o dos Guararapes',\n",
        "        'Recife (Codecipe / Santo Amaro)': 'Recife',\n",
        "        'Recife (V√°rzea)': 'Recife',\n",
        "        'S√£o Louren√ßo da Mata (Tapacur√°)': 'S√£o Louren√ßo da Mata'\n",
        "    }\n",
        "\n",
        "    df_chuva['Posto'] = df_chuva['Posto'].replace(mapeamento_cidades)\n",
        "\n",
        "    # 5. Convers√£o num√©rica robusta\n",
        "    day_cols = [str(i) for i in range(1,32)]\n",
        "    for col in day_cols + ['Acumulado']:\n",
        "        df_chuva[col] = (\n",
        "            df_chuva[col]\n",
        "            .str.replace('[^0-9,]', '', regex=True)\n",
        "            .str.replace(',', '.')\n",
        "            .replace('', '0')\n",
        "            .astype(float)\n",
        "        )\n",
        "\n",
        "    # 6. Consist√™ncia final\n",
        "    df_chuva = df_chuva.groupby(['M√™s/Ano', 'Posto']).first().reset_index()\n",
        "\n",
        "    return df_chuva\n",
        "\n",
        "def processar_dados_chuva():\n",
        "    \"\"\"Processa e formata os dados pluviom√©tricos\"\"\"\n",
        "    print(\"\\nüåßÔ∏è PROCESSANDO DADOS DE CHUVA\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # C√≥digo de pr√©-processamento anterior (mantido)\n",
        "    df_chuva = preprocessar_dados_chuva()\n",
        "    print(\"\\n‚úÖ Cidades padronizadas:\", df_chuva['Posto'].unique())\n",
        "    print(\"‚úÖ Formato temporal:\", df_chuva['M√™s/Ano'].unique()[:5])\n",
        "    print(\"‚úÖ Exemplo de dados:\\n\", df_chuva.sample(3))\n",
        "\n",
        "    # Converter o formato wide para long (uma linha por dia/m√™s/cidade)\n",
        "    df_chuva_reform = df_chuva.melt(\n",
        "        id_vars=['Posto', 'M√™s/Ano'],\n",
        "        value_vars=[str(i) for i in range(1, 32)],\n",
        "        var_name='Dia',\n",
        "        value_name='Chuva_mm'\n",
        "    )\n",
        "\n",
        "    # Converter dia para inteiro\n",
        "    df_chuva_reform['Dia'] = df_chuva_reform['Dia'].astype(int)\n",
        "\n",
        "    return df_chuva_reform\n",
        "\n",
        "def corrigir_df_rmr(df):\n",
        "    # 1. Converter datas\n",
        "    df['DTOBITO'] = pd.to_datetime(\n",
        "        df['DTOBITO'].astype(str).str.zfill(8),\n",
        "        format='%d%m%Y',\n",
        "        errors='coerce'\n",
        "    )\n",
        "\n",
        "    # 2. Ajustar encoding\n",
        "    df['ocor_MUNNOME'] = (\n",
        "        df['ocor_MUNNOME']\n",
        "        .str.encode('latin-1').str.decode('utf-8', errors='ignore')\n",
        "        .replace({\n",
        "            'S√É¬£o Louren√É¬ßo da Mata': 'S√£o Louren√ßo da Mata',\n",
        "            'Jaboat√É¬£o dos Guararapes': 'Jaboat√£o dos Guararapes',\n",
        "            'Ilha de Itamarac√É¬°': 'Ilha de Itamarac√°',\n",
        "            'Ara√É¬ßoiaba': 'Ara√ßoiaba'\n",
        "        })\n",
        "    )\n",
        "\n",
        "    # 3. Mapear vari√°veis categ√≥ricas\n",
        "    df['SEXO'] = df['SEXO'].map({\n",
        "        1: 'Masculino',\n",
        "        2: 'Feminino',\n",
        "        0: 'Ignorado'\n",
        "    })\n",
        "\n",
        "    # 4. Corrigir idade (supondo que idade est√° em dias)\n",
        "    if 'idade_obito_anos' not in df.columns:\n",
        "        df['idade_obito_anos'] = df['IDADE'] // 365  # Se IDADE estiver em dias\n",
        "\n",
        "    # 5. Remover colunas vazias\n",
        "    cols_vazias = [col for col in df.columns if df[col].isna().all()]\n",
        "    df = df.drop(columns=cols_vazias)\n",
        "\n",
        "    return df\n",
        "\n",
        "# =====================================\n",
        "# DADOS DE REFER√äNCIA (RMR - Pernambuco)\n",
        "# =====================================\n",
        "# C√≥digos IBGE dos munic√≠pios da RMR (6 d√≠gitos, como aparece no seu DataFrame)\n",
        "codigos_rmr_6digitos = [\n",
        "    '261160',  # Recife\n",
        "    '260790',  # Jaboat√£o dos Guararapes\n",
        "    '260960',  # Olinda\n",
        "    '261070',  # Paulista\n",
        "    '260290',  # Cabo de Santo Agostinho\n",
        "    '260345',  # Camaragibe\n",
        "    '261370',  # S√£o Louren√ßo da Mata\n",
        "    '260680',  # Igarassu\n",
        "    '260005',  # Abreu e Lima\n",
        "    '260720',  # Ipojuca\n",
        "    '260940',  # Moreno\n",
        "    '260105',  # Ara√ßoiaba\n",
        "    '260775',  # Itapissuma\n",
        "    '260760'   # Itamarac√°\n",
        "]\n",
        "\n",
        "# Nomes correspondentes aos c√≥digos\n",
        "nomes_municipios = {\n",
        "    '260005': 'Abreu e Lima',\n",
        "    '260105': 'Ara√ßoiaba',\n",
        "    '260290': 'Cabo de Santo Agostinho',\n",
        "    '260345': 'Camaragibe',\n",
        "    '260680': 'Igarassu',\n",
        "    '260720': 'Ipojuca',\n",
        "    '260760': 'Itamarac√°',\n",
        "    '260775': 'Itapissuma',\n",
        "    '260790': 'Jaboat√£o dos Guararapes',\n",
        "    '260940': 'Moreno',\n",
        "    '260960': 'Olinda',\n",
        "    '261070': 'Paulista',\n",
        "    '261160': 'Recife',\n",
        "    '261370': 'S√£o Louren√ßo da Mata'\n",
        "}\n",
        "\n",
        "def processar_dados_mortalidade(df):\n",
        "    # Deixar apenas Pernambuco\n",
        "    df_pe = df[df['ocor_SIGLA_UF'] == 'PE']\n",
        "\n",
        "    # Criar uma coluna tempor√°ria com os 6 primeiros d√≠gitos de CODMUNOCOR\n",
        "    df_pe['CODMUNOCOR'] = df_pe['CODMUNOCOR'].astype(str).str[:6]\n",
        "\n",
        "    # Filtrar apenas os munic√≠pios da RMR\n",
        "    df_rmr = df_pe[df_pe['CODMUNOCOR'].isin(codigos_rmr_6digitos)].copy()\n",
        "\n",
        "    # Adicionar nomes dos munic√≠pios\n",
        "    df_rmr['NOME_MUNICIPIO'] = df_rmr['CODMUNOCOR'].map(nomes_municipios)\n",
        "\n",
        "    # Aplicar corre√ß√µes\n",
        "    df_rmr_corrigido = corrigir_df_rmr(df_rmr)\n",
        "\n",
        "    # Verificar resultados\n",
        "    print(\"\\nüîç Datas convertidas (exemplo):\", df_rmr_corrigido['DTOBITO'].head(3))\n",
        "    print(\"\\nüåÜ Munic√≠pios normalizados:\", df_rmr_corrigido['ocor_MUNNOME'].unique())\n",
        "    print(\"\\nüë• Distribui√ß√£o por sexo:\\n\", df_rmr_corrigido['SEXO'].value_counts())\n",
        "\n",
        "    # Adicionar ao c√≥digo de corre√ß√£o (etapa 2)\n",
        "    # Modificar df_rmr_corrigido em vez de df\n",
        "    df_rmr_corrigido['ocor_MUNNOME'] = df_rmr_corrigido['ocor_MUNNOME'].replace('Ilha de Itamarac√°', 'Itamarac√°')\n",
        "\n",
        "    df_analise = df_rmr_corrigido[df_rmr_corrigido['SEXO'].isin(['Masculino', 'Feminino'])]\n",
        "\n",
        "    # Criar colunas de jun√ß√£o\n",
        "    df_rmr_corrigido['MES_ANO'] = df_rmr_corrigido['DTOBITO'].dt.strftime('%m/%Y')\n",
        "    df_rmr_corrigido['DIA'] = df_rmr_corrigido['DTOBITO'].dt.day\n",
        "\n",
        "    # Criar colunas de jun√ß√£o no df_rmr_corrigido\n",
        "    df_rmr_corrigido['MES_ANO'] = df_rmr_corrigido['DTOBITO'].dt.strftime('%m/%Y')\n",
        "    df_rmr_corrigido['DIA'] = df_rmr_corrigido['DTOBITO'].dt.day\n",
        "\n",
        "    return df_rmr_corrigido\n",
        "\n",
        "# ========================================================\n",
        "#               FUN√á√ÉO PRINCIPAL\n",
        "# ========================================================\n",
        "\n",
        "# Etapa 1: Carregar dados\n",
        "df_mortalidade = carregar_dados_mortalidade()\n",
        "df_chuva = processar_dados_chuva()\n",
        "\n",
        "# Etapa 2: Processamento e merge\n",
        "df_processado = processar_dados_mortalidade(df_mortalidade)\n",
        "df_final = pd.merge(\n",
        "    df_processado,\n",
        "    df_chuva,\n",
        "    left_on=['ocor_MUNNOME', 'MES_ANO', 'DIA'],\n",
        "    right_on=['Posto', 'M√™s/Ano', 'Dia'],\n",
        "    how='left'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTW4NMF70UQw"
      },
      "source": [
        "### üìä Compara√ß√£o Di√°ria: √ìbitos e Chuvas na RMR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uzzfVSI2hu-3"
      },
      "outputs": [],
      "source": [
        "def comparar_rmr_dia(data_input, cidade, df, top_n=10):\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    rmr_cidades = [\n",
        "        'Recife', 'Igarassu', 'Camaragibe', 'Ara√ßoiaba', 'Cabo de Santo Agostinho',\n",
        "        'S√£o Louren√ßo da Mata', 'Itamarac√°', 'Jaboat√£o dos Guararapes', 'Paulista',\n",
        "        'Ipojuca', 'Moreno', 'Olinda', 'Abreu e Lima', 'Itapissuma'\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        data = pd.to_datetime(data_input).date()\n",
        "    except:\n",
        "        print(\"‚ùå Data inv√°lida. Use o formato 'YYYY-MM-DD'.\")\n",
        "        return\n",
        "\n",
        "    df_rmr_dia = df[\n",
        "        (df['ocor_MUNNOME'].isin(rmr_cidades)) &\n",
        "        (pd.to_datetime(df['data_obito']).dt.date == data)\n",
        "    ]\n",
        "\n",
        "    if df_rmr_dia.empty:\n",
        "        print(f\"‚ö†Ô∏è Nenhum dado encontrado para a RMR em {data}.\")\n",
        "        return\n",
        "\n",
        "    dados_cidade = df_rmr_dia[df_rmr_dia['ocor_MUNNOME'].str.upper() == cidade.upper()]\n",
        "\n",
        "    if dados_cidade.empty:\n",
        "        print(f\"‚ö†Ô∏è Nenhum dado encontrado para {cidade.title()} em {data}.\")\n",
        "        return\n",
        "\n",
        "    # Preparar dados\n",
        "    causas = dados_cidade['CAUSABAS'].value_counts().head(top_n)\n",
        "    agrupado = df_rmr_dia.groupby('ocor_MUNNOME').agg({\n",
        "        'DTOBITO': 'count',\n",
        "        'Chuva_mm': 'mean'\n",
        "    }).rename(columns={'DTOBITO': 'Total_Obitos', 'Chuva_mm': 'Media_Chuva_mm'}).fillna(0)\n",
        "\n",
        "    rmr_existentes = [c for c in rmr_cidades if c in agrupado.index]\n",
        "    agrupado = agrupado.loc[rmr_existentes]\n",
        "    cores = ['red' if cidade.lower() != mun.lower() else 'darkblue' for mun in agrupado.index]\n",
        "\n",
        "    # Criar dois gr√°ficos lado a lado\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "    # Pizza\n",
        "    ax1.pie(causas, labels=causas.index, autopct='%1.1f%%', startangle=140,\n",
        "            colors=sns.color_palette('Reds', n_colors=top_n))\n",
        "    ax1.set_title(f'{cidade.title()} - {data}\\nTop {top_n} Causas de √ìbito (CAUSABAS)')\n",
        "\n",
        "    # Barras + linha\n",
        "    sns.barplot(x=agrupado.index, y=agrupado['Total_Obitos'], palette=cores, ax=ax2)\n",
        "    ax2.set_ylabel('Total de √ìbitos', color='black')\n",
        "    ax2.set_xlabel('')\n",
        "    ax2.set_xticklabels(agrupado.index, rotation=45, ha='right')\n",
        "\n",
        "    ax3 = ax2.twinx()\n",
        "    sns.lineplot(x=agrupado.index, y=agrupado['Media_Chuva_mm'], color='blue', marker='o', label='Chuva M√©dia (mm)', ax=ax3)\n",
        "    ax3.set_ylabel('M√©dia de Chuva (mm)', color='blue')\n",
        "    ax3.tick_params(axis='y', labelcolor='blue')\n",
        "\n",
        "    ax2.set_title(f'Comparativo por Cidade na RMR - {data}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Resumo\n",
        "    print(f\"\\nüìÖ Data: {data}\")\n",
        "    print(f\"üèôÔ∏è Cidade: {cidade.title()}\")\n",
        "    print(f\"üíÄ √ìbitos: {len(dados_cidade)}\")\n",
        "    print(f\"‚òî Chuva: {dados_cidade['Chuva_mm'].mean():.2f} mm\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjJWUKe5HWMl"
      },
      "source": [
        "# Intera√ß√µes e Gr√°ficos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MofbDYnm0b5D"
      },
      "source": [
        "### üîó Correla√ß√£o entre Chuva e √ìbitos por Causas Infecciosas (CID-W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBL8y444Wwp0",
        "outputId": "e4a6f035-aa29-4850-f14b-81b407689e65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recife: -0.14\n",
            "Igarassu: -0.22\n",
            "Camaragibe: -0.34\n",
            "Ara√ßoiaba: -0.17\n",
            "Cabo de Santo Agostinho: -0.19\n",
            "S√£o Louren√ßo da Mata: -0.27\n",
            "Itamarac√°: 0.18\n",
            "Jaboat√£o dos Guararapes: -0.13\n",
            "Paulista: -0.19\n",
            "Ipojuca: -0.27\n",
            "Moreno: -0.13\n",
            "Olinda: -0.07\n",
            "Abreu e Lima: 0.02\n",
            "Itapissuma: -0.37\n"
          ]
        }
      ],
      "source": [
        "df_final = df_final[df_final['CAUSABAS'].str.startswith(('W'), na=False)]\n",
        "df_final = df_final.rename(columns={'CONTADOR': 'Total_Obitos'})\n",
        "\n",
        "for cidade in df_final['ocor_MUNNOME'].unique():\n",
        "    df_cidade = df_final[df_final['ocor_MUNNOME'] == cidade]\n",
        "    corr_local = df_cidade[['Chuva_mm', 'Total_Obitos']].corr().iloc[0, 1]\n",
        "    print(f\"{cidade}: {corr_local:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "qTiGt49hdNIN",
        "outputId": "ce88e7ba-7328-4719-f937-207baba2f88b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Nenhum dado encontrado para a RMR em 2024-05-01.\n"
          ]
        }
      ],
      "source": [
        "comparar_rmr_dia(\"2024-05-1\", \"Recife\", df_final)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "uD1pkQolIsTm",
        "Bhzbfm970Ivp",
        "jghaSZX30NQa",
        "kTW4NMF70UQw",
        "GjJWUKe5HWMl"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
